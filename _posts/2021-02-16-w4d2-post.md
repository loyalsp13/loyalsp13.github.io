---
title: "[U] Week 4 (Day 2)"
date: 2021-02-16
categories: boostcamp AI Tech
---
# Lecture

Natural language processing

* RNN

    * similar with Week 3 (Day 4) post

    * each step's target becomes next step's input

* LSTM , GRU

    * range of sigmoid output (0, 1) -> represent how much information to store

    * each gate controlls C_(t-1)

    * C_t~ is not directly added to C_(t-1) -> input gate determines information of C_t~

    * GRU has faster speed (only has hidden state)

* implementation

    * RNN

        * initialize h_0 to zeros

        * nn.rnn generate last hidden state -> text classification
        
        * PackedSequence = make batches with padded senteces seperately

        * teacher forcing = pass real target value to input instead output of previous cell

    * LSTM, GRU

        * GRU can be used like RNN

        * can stop generate words when end token is generated

        * bidirectional network can be used

# Assignment

Preprocessing NLP data

# Peer Session

* review Word2vec, Globe

