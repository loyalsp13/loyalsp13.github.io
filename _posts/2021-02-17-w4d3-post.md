---
title: "[U] Week 4 (Day 3)"
date: 2021-02-17
categories: boostcamp AI Tech
---
# Lecture

Natural language processing

* Seq2Seq with attention

    * encoder hidden state output * decoder hidden state output -> softmax -> weighted sum of encoder hidden state output = attention

    * dot product can be replaced with concat, fc layer

    * solves the bottleneck problem, vanishing gradient problem, provides some interpretability

* Beam Search

    * greedy decoding has no way to undo decisions -> try all possible sequences

    * generate k hypotheses for each step -> compare sum of log probability

    * from 'sos' to 'eos' , normalize with sentence length

* BLEU score

    * precision, recall and F-measure are not effective metric to evaluate NLP

    * BLEU score us N-gram overlap to check order and duplication of words

* implementation

    * Seq2Seq , Seq2Seq with Attention (dot product, concat)

# Assignment

training NMT model with fairseq

# Peer Session

* review LSTM, GRU

